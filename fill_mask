import numpy as np
import torch
import logging
from typing import Any, Dict, List, Union, Optional
from .base import Pipeline

# Core Dependencies
from core.workflow import Workflow
from core.environment import Environment

logger = logging.getLogger(__name__)

class OffloadingFillMaskPipeline(Pipeline):
    """
    Task offloading 'Fill-Mask' pipeline. 
    Predicts the best location for a specific task given a partial policy.
    
    Analogy to FillMaskPipeline:
    - [MASK] Token -> Task with assigned location -1 (Unknown)
    - Vocabulary -> Available Location IDs {0, 1, 2, ...}
    - Sequence -> The full Placement Policy vector p
    """

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # Default top_k locations to return for the mask
        self.top_k = kwargs.get("top_k", 3)

    def _sanitize_parameters(self, top_k=None, targets=None, **kwargs):
        """Standardized parameter sanitizer for masking context."""
        postprocess_params = {}
        if top_k is not None:
            postprocess_params["top_k"] = top_k
        if targets is not None:
            # targets limits the search to specific location types (e.g., only Edge)
            postprocess_params["target_ids"] = targets
        return {}, {}, postprocess_params

    def preprocess(self, inputs: Dict, **kwargs):
        """
        Validates that exactly one task is 'masked' (set to -1).
        """
        policy = inputs.get("partial_policy", [])
        masked_indices = [i for i, loc in enumerate(policy) if loc == -1]
        
        if len(masked_indices) != 1:
            raise ValueError("Offloading fill-mask requires exactly one task assigned to -1.")

        workflow_obj = Workflow.from_experiment_dict(inputs.get("workflow", {}))
        return {
            "workflow": workflow_obj,
            "env": inputs.get("env", {}),
            "partial_policy": policy,
            "masked_index": masked_indices[0] + 1, # Task IDs are 1-indexed
            "params": inputs.get("costs", {})
        }

    def _forward(self, model_inputs):
        """
        Uses the Evaluator Agent to predict the best 'fill' for the mask.
        """
        env_dict = model_inputs["env"]
        location_ids = sorted(env_dict.get('locations', {}).keys())
        
        # Test every possible location in the 'vocab' for the masked task
        results = []
        for loc in location_ids:
            # Create a candidate policy by filling the mask
            candidate_policy = list(model_inputs["partial_policy"])
            candidate_policy[model_inputs["masked_index"] - 1] = loc
            
            # Evaluate cost U(w,p) for this completion
            cost = self.model.evaluator.total_offloading_cost(
                model_inputs["workflow"], 
                {i+1: l for i, l in enumerate(candidate_policy)}, 
                model_inputs["env"]
            )
            results.append({"token": loc, "score": cost, "policy": candidate_policy})
            
        return {"predictions": results, "masked_task": model_inputs["masked_index"]}

    def postprocess(self, model_outputs, top_k=5, target_ids=None):
        """
        Returns the top predictions for the masked task.
        """
        preds = model_outputs["predictions"]
        
        # Filter by targets if provided (e.g., 'Only suggest Cloud locations')
        if target_ids is not None:
            preds = [p for p in preds if p["token"] in target_ids]

        # Sort by best (lowest) cost and take top_k
        sorted_preds = sorted(preds, key=lambda x: x["score"])[:top_k]
        
        return [
            {
                "sequence": f"Completed Policy: {p['policy']}",
                "score": p["score"],
                "token": p["token"],
                "token_str": f"Location {p['token']}",
                "masked_task": model_outputs["masked_task"]
            } for p in sorted_preds
        ]