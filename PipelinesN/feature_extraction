import numpy as np
import torch
from typing import Any, Dict, List, Union
from .base import Pipeline

# Core Dependencies
from core.workflow import Workflow
from core.memory_manager import WorkflowMemory

class OffloadingFeatureExtractionPipeline(Pipeline):
    """
    Feature extraction pipeline for offloading scenarios.
    Extracts the structural and physical 'hidden states' (features) of a DAG 
    to enable historical similarity search.
    """

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # The 'Memory Manager' acts as our Feature Extractor
        self.feature_extractor = WorkflowMemory()

    def _sanitize_parameters(self, return_tensors=None, **kwargs):
        """Standardized parameter sanitizer."""
        postprocess_params = {}
        if return_tensors is not None:
            postprocess_params["return_tensors"] = return_tensors
        return {}, {}, postprocess_params

    def preprocess(self, inputs: Dict, **kwargs) -> Dict:
        """
        Equivalent to Tokenization. Converts raw JSON into a structured 
        Workflow object.
        """
        workflow_obj = Workflow.from_experiment_dict(inputs.get("workflow", {}))
        return {
            "workflow": workflow_obj,
            "workflow_dict": inputs.get("workflow", {}),
            "env": inputs.get("env", {}),
            "params": inputs.get("costs", {})
        }

    def _forward(self, model_inputs: Dict) -> Dict:
        """
        Extracts the numerical 'embeddings' (features) of the scenario 
       .
        """
        # Extract workflow-specific features
        wf_features = self.feature_extractor.extract_workflow_features(
            model_inputs["workflow_dict"]
        )
        
        # Extract environment-specific features
        env_features = self.feature_extractor.extract_environment_features(
            model_inputs["env"]
        )
        
        # Combine into a normalized feature vector (the 'hidden state')
        #
        feature_vector = self.feature_extractor.compute_feature_vector(
            wf_features, env_features
        )
        
        return {"feature_vector": feature_vector}

    def postprocess(self, model_outputs: Dict, return_tensors=False):
        """
        Returns the feature vector as a list or a torch.Tensor 
       .
        """
        vec = model_outputs["feature_vector"]
        if return_tensors:
            return torch.tensor(vec)
        return vec.tolist()

    def __call__(self, inputs: Dict, **kwargs) -> Any:
        """
        Extract the features of the offloading scenario.
        """
        return super().__call__(inputs, **kwargs)